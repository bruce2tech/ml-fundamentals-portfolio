{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"] = 72\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (891, 11)\n",
      "Test data shape: (418, 10)\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Store PassengerId for test set\n",
    "test_ids = df_test['PassengerId']\n",
    "\n",
    "# Drop PassengerId from both datasets\n",
    "df_train = df_train.drop('PassengerId', axis=1)\n",
    "df_test = df_test.drop('PassengerId', axis=1)\n",
    "\n",
    "print(\"Training data shape:\", df_train.shape)\n",
    "print(\"Test data shape:\", df_test.shape)\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      Survived  Pclass                                               Name  \\\n",
       "0           0       3                            Braund, Mr. Owen Harris   \n",
       "1           1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2           1       3                             Heikkinen, Miss. Laina   \n",
       "3           1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4           0       3                           Allen, Mr. William Henry   \n",
       "..        ...     ...                                                ...   \n",
       "886         0       2                              Montvila, Rev. Juozas   \n",
       "887         1       1                       Graham, Miss. Margaret Edith   \n",
       "888         0       3           Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "889         1       1                              Behr, Mr. Karl Howell   \n",
       "890         0       3                                Dooley, Mr. Patrick   \n",
       "\n",
       "        Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0      male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1    female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2    female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3    female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4      male  35.0      0      0            373450   8.0500   NaN        S  \n",
       "..      ...   ...    ...    ...               ...      ...   ...      ...  \n",
       "886    male  27.0      0      0            211536  13.0000   NaN        S  \n",
       "887  female  19.0      0      0            112053  30.0000   B42        S  \n",
       "888  female   NaN      1      2        W./C. 6607  23.4500   NaN        S  \n",
       "889    male  26.0      0      0            111369  30.0000  C148        C  \n",
       "890    male  32.0      0      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 11 columns]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data types\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Survived      int64\n",
       "Pclass        int64\n",
       "Name         object\n",
       "Sex          object\n",
       "Age         float64\n",
       "SibSp         int64\n",
       "Parch         int64\n",
       "Ticket       object\n",
       "Fare        float64\n",
       "Cabin        object\n",
       "Embarked     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do we have NaN in our dataset?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Survived    False\n",
       "Pclass      False\n",
       "Name        False\n",
       "Sex         False\n",
       "Age          True\n",
       "SibSp       False\n",
       "Parch       False\n",
       "Ticket      False\n",
       "Fare        False\n",
       "Cabin        True\n",
       "Embarked     True\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing value percentages:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Survived     0.000000\n",
       "Pclass       0.000000\n",
       "Name         0.000000\n",
       "Sex          0.000000\n",
       "Age         19.865320\n",
       "SibSp        0.000000\n",
       "Parch        0.000000\n",
       "Ticket       0.000000\n",
       "Fare         0.000000\n",
       "Cabin       77.104377\n",
       "Embarked     0.224467\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore training data\n",
    "display(df_train.head)\n",
    "print('data types')\n",
    "display(df_train.dtypes)\n",
    "\n",
    "print('Do we have NaN in our dataset?')\n",
    "display(df_train.isnull().any())\n",
    "\n",
    "print(\"Missing value counts:\")\n",
    "display(df_train.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing value percentages:\")\n",
    "display(df_train.isnull().sum() / len(df_train) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      Pclass                                          Name     Sex   Age  \\\n",
       "0         3                              Kelly, Mr. James    male  34.5   \n",
       "1         3              Wilkes, Mrs. James (Ellen Needs)  female  47.0   \n",
       "2         2                     Myles, Mr. Thomas Francis    male  62.0   \n",
       "3         3                              Wirz, Mr. Albert    male  27.0   \n",
       "4         3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0   \n",
       "..      ...                                           ...     ...   ...   \n",
       "413       3                            Spector, Mr. Woolf    male   NaN   \n",
       "414       1                  Oliva y Ocana, Dona. Fermina  female  39.0   \n",
       "415       3                  Saether, Mr. Simon Sivertsen    male  38.5   \n",
       "416       3                           Ware, Mr. Frederick    male   NaN   \n",
       "417       3                      Peter, Master. Michael J    male   NaN   \n",
       "\n",
       "     SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0        0      0              330911    7.8292   NaN        Q  \n",
       "1        1      0              363272    7.0000   NaN        S  \n",
       "2        0      0              240276    9.6875   NaN        Q  \n",
       "3        0      0              315154    8.6625   NaN        S  \n",
       "4        1      1             3101298   12.2875   NaN        S  \n",
       "..     ...    ...                 ...       ...   ...      ...  \n",
       "413      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "414      0      0            PC 17758  108.9000  C105        C  \n",
       "415      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416      0      0              359309    8.0500   NaN        S  \n",
       "417      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 10 columns]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data types\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pclass        int64\n",
       "Name         object\n",
       "Sex          object\n",
       "Age         float64\n",
       "SibSp         int64\n",
       "Parch         int64\n",
       "Ticket       object\n",
       "Fare        float64\n",
       "Cabin        object\n",
       "Embarked     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do we have NaN in our dataset?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pclass      False\n",
       "Name        False\n",
       "Sex         False\n",
       "Age          True\n",
       "SibSp       False\n",
       "Parch       False\n",
       "Ticket      False\n",
       "Fare         True\n",
       "Cabin        True\n",
       "Embarked    False\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age          86\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          1\n",
       "Cabin       327\n",
       "Embarked      0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing value percentages:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pclass       0.000000\n",
       "Name         0.000000\n",
       "Sex          0.000000\n",
       "Age         20.574163\n",
       "SibSp        0.000000\n",
       "Parch        0.000000\n",
       "Ticket       0.000000\n",
       "Fare         0.239234\n",
       "Cabin       78.229665\n",
       "Embarked     0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore test data\n",
    "display(df_test.head)\n",
    "print('data types')\n",
    "display(df_test.dtypes)\n",
    "\n",
    "print('Do we have NaN in our dataset?')\n",
    "display(df_test.isnull().any())\n",
    "\n",
    "print(\"Missing value counts:\")\n",
    "display(df_test.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing value percentages:\")\n",
    "display(df_test.isnull().sum() / len(df_test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputing Age\n",
      "Filled missing Age with mean: 29.70\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nImputing Age\")\n",
    "\n",
    "age_mean = df_train['Age'].mean()\n",
    "df_train['Age'] = df_train['Age'].fillna(age_mean)\n",
    "\n",
    "# IMPORTANT: Use training mean for test set too (avoid data leakage)\n",
    "\n",
    "df_test['Age'] = df_test['Age'].fillna(age_mean)\n",
    "\n",
    "print(f\"Filled missing Age with mean: {age_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Add HasCabin feature\n",
      "Created HasCabin feature (train): 204 had cabin info\n",
      "Created HasCabin feature (test): 91 had cabin info\n"
     ]
    }
   ],
   "source": [
    "# Cabin Feature is missing 77% of data - Feature Engineer a HasCabin Feature\n",
    "# The presence of cabin info could be an indicator of surviving\n",
    "\n",
    "print(\"\\nAdd HasCabin feature\")\n",
    "df_train['HasCabin'] = df_train['Cabin'].notna().astype(int)\n",
    "df_test['HasCabin'] = df_test['Cabin'].notna().astype(int)\n",
    "\n",
    "print(f\"Created HasCabin feature (train): {df_train['HasCabin'].sum()} had cabin info\")\n",
    "print(f\"Created HasCabin feature (test): {df_test['HasCabin'].sum()} had cabin info\")\n",
    "\n",
    "# Now drop the original Cabin column\n",
    "df_train = df_train.drop('Cabin', axis=1)\n",
    "df_test = df_test.drop('Cabin', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputing Fare\n",
      "Filled missing test Fare with median: 14.45\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nImputing Fare\")\n",
    "if df_test['Fare'].isnull().any():\n",
    "    fare_median = df_train['Fare'].median()\n",
    "    df_test['Fare'] = df_test['Fare'].fillna(fare_median)\n",
    "    print(f\"Filled missing test Fare with median: {fare_median:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing Embarked\n",
      "Filled missing train Embarked with mode: S\n"
     ]
    }
   ],
   "source": [
    "# Replace 2 missing values in Embarked feature with the mode of the feature\n",
    "embarked_mode = df_train['Embarked'].mode()[0]\n",
    "print(\"Imputing Embarked\")\n",
    "df_train['Embarked'] = df_train['Embarked'].fillna(embarked_mode)\n",
    "print(f'Filled missing train Embarked with mode: {embarked_mode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "AFTER IMPUTATION - Missing values check:\n",
      "\n",
      "Training set:\n",
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Ticket      0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "HasCabin    0\n",
      "dtype: int64\n",
      "\n",
      "Test set:\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Ticket      0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "HasCabin    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"AFTER IMPUTATION - Missing values check:\")\n",
    "print(\"\\nTraining set:\")\n",
    "print(df_train.isnull().sum())\n",
    "print(\"\\nTest set:\")\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual names do not provide much information.\n",
    "# But a person's title could indicate status - Feature engineer 'Title' column\n",
    "# Use regex function to extract title from 'Name' feature\n",
    "def extract_title(name):\n",
    "    \"\"\"Extract title from name string\"\"\"\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique titles in training set:\n",
      "Title\n",
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Mlle          2\n",
      "Major         2\n",
      "Col           2\n",
      "Countess      1\n",
      "Capt          1\n",
      "Ms            1\n",
      "Sir           1\n",
      "Lady          1\n",
      "Mme           1\n",
      "Don           1\n",
      "Jonkheer      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique titles in test set:\n",
      "Title\n",
      "Mr        240\n",
      "Miss       78\n",
      "Mrs        72\n",
      "Master     21\n",
      "Col         2\n",
      "Rev         2\n",
      "Ms          1\n",
      "Dr          1\n",
      "Dona        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train['Title'] = df_train['Name'].apply(extract_title)\n",
    "df_test['Title'] = df_test['Name'].apply(extract_title)\n",
    "\n",
    "print(\"Unique titles in training set:\")\n",
    "print(df_train['Title'].value_counts())\n",
    "print(\"\\nUnique titles in test set:\")\n",
    "print(df_test['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group rare titles into categories\n",
    "\n",
    "def simplify_title(title):\n",
    "    \"\"\"Group rare titles into common categories\"\"\"\n",
    "    if title in ['Mr']:\n",
    "        return 'Mr'\n",
    "    elif title in ['Miss', 'Mlle', 'Ms']:  # Mlle = Mademoiselle (French Miss)\n",
    "        return 'Miss'\n",
    "    elif title in ['Mrs', 'Mme']:  # Mme = Madame (French Mrs)\n",
    "        return 'Mrs'\n",
    "    elif title in ['Master']:\n",
    "        return 'Master'\n",
    "    elif title in ['Dr', 'Rev', 'Col', 'Major', 'Capt']:  # Professional/Military\n",
    "        return 'Officer'\n",
    "    else:  # Rare nobility titles: Lady, Sir, Countess, Don, Dona, Jonkheer\n",
    "        return 'Royalty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated value counts:\n",
      "Title\n",
      "Mr         517\n",
      "Miss       185\n",
      "Mrs        126\n",
      "Master      40\n",
      "Officer     18\n",
      "Royalty      5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Survival by simplified Title:\n",
      "Title\n",
      "Mrs        0.793651\n",
      "Miss       0.702703\n",
      "Royalty    0.600000\n",
      "Master     0.575000\n",
      "Officer    0.277778\n",
      "Mr         0.156673\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now simplify\n",
    "df_train['Title'] = df_train['Title'].apply(simplify_title)\n",
    "df_test['Title'] = df_test['Title'].apply(simplify_title)\n",
    "\n",
    "print(\"Updated value counts:\")\n",
    "print(df_train['Title'].value_counts())\n",
    "print(\"\\nSurvival by simplified Title:\")\n",
    "print(df_train.groupby('Title')['Survived'].mean().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Family size distribution (train):\n",
      "FamilySize\n",
      "1     537\n",
      "2     161\n",
      "3     102\n",
      "4      29\n",
      "5      15\n",
      "6      22\n",
      "7      12\n",
      "8       6\n",
      "11      7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number traveling alone: 537\n",
      "Number with family: 354\n"
     ]
    }
   ],
   "source": [
    "# People have different survival behaviors when they are alone vs in a tribe (family).\n",
    "# Feature engineer FamilySize and \n",
    "# FamilySize = number of siblings/spouses + number of parents/children + self\n",
    "\n",
    "# sibsp: The dataset defines family relations in this way...\n",
    "# Sibling = brother, sister, stepbrother, stepsister\n",
    "# Spouse = husband, wife (mistresses and fiancÃ©s were ignored)\n",
    "\n",
    "# parch: The dataset defines family relations in this way...\n",
    "# Parent = mother, father\n",
    "# Child = daughter, son, stepdaughter, stepson\n",
    "\n",
    "df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1\n",
    "df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1\n",
    "\n",
    "# IsAlone = 1 if traveling alone, 0 otherwise\n",
    "df_train['IsAlone'] = (df_train['FamilySize'] == 1).astype(int)\n",
    "df_test['IsAlone'] = (df_test['FamilySize'] == 1).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Family size distribution (train):\")\n",
    "print(df_train['FamilySize'].value_counts().sort_index())\n",
    "print(f\"\\nNumber traveling alone: {df_train['IsAlone'].sum()}\")\n",
    "print(f\"Number with family: {(df_train['IsAlone'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "SURVIVAL ANALYSIS:\n",
      "\n",
      "Survival rate by Title:\n",
      "Title\n",
      "Mrs        0.793651\n",
      "Miss       0.702703\n",
      "Royalty    0.600000\n",
      "Master     0.575000\n",
      "Officer    0.277778\n",
      "Mr         0.156673\n",
      "Name: Survived, dtype: float64\n",
      "\n",
      "Survival rate by FamilySize:\n",
      "FamilySize\n",
      "4     0.724138\n",
      "3     0.578431\n",
      "2     0.552795\n",
      "7     0.333333\n",
      "1     0.303538\n",
      "5     0.200000\n",
      "6     0.136364\n",
      "8     0.000000\n",
      "11    0.000000\n",
      "Name: Survived, dtype: float64\n",
      "\n",
      "Survival rate by IsAlone:\n",
      "IsAlone\n",
      "0    0.505650\n",
      "1    0.303538\n",
      "Name: Survived, dtype: float64\n",
      "\n",
      "Survival rate by Sex:\n",
      "Sex\n",
      "female    0.742038\n",
      "male      0.188908\n",
      "Name: Survived, dtype: float64\n",
      "\n",
      "Survival rate by Pclass:\n",
      "Pclass\n",
      "1    0.629630\n",
      "2    0.472826\n",
      "3    0.242363\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Explore survival rates using key features\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SURVIVAL ANALYSIS:\")\n",
    "print(\"\\nSurvival rate by Title:\")\n",
    "print(df_train.groupby('Title')['Survived'].mean().sort_values(ascending=False))\n",
    "\n",
    "print(\"\\nSurvival rate by FamilySize:\")\n",
    "print(df_train.groupby('FamilySize')['Survived'].mean().sort_values(ascending=False))\n",
    "\n",
    "print(\"\\nSurvival rate by IsAlone:\")\n",
    "print(df_train.groupby('IsAlone')['Survived'].mean())\n",
    "\n",
    "print(\"\\nSurvival rate by Sex:\")\n",
    "print(df_train.groupby('Sex')['Survived'].mean())\n",
    "\n",
    "print(\"\\nSurvival rate by Pclass:\")\n",
    "print(df_train.groupby('Pclass')['Survived'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analyis tells us the \"women and children first\" policy was implemented. Females had a 74% survival rate compared to males at 19%. Characteristic of a chivalrous culture.\n",
    "The Pclass indicates wealth. 1st class passengers chance of survival was 63%, 2nd class: 47%, 3rd class: 24%. Having wealth increased chances of survival. Not much has changed regarding this fact.\n",
    "Those with Family_sizes of 3-4 had the best chance of survival over larger families and those traveling solo or with one other person. Large families, likely were caught in the chaos of the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping features:\n",
      "Train columns: ['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked', 'HasCabin', 'Title', 'FamilySize', 'IsAlone']\n",
      "\n",
      "After dropping features:\n",
      "Train columns: ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'HasCabin', 'Title', 'FamilySize', 'IsAlone']\n"
     ]
    }
   ],
   "source": [
    "# Drop useless features\n",
    "print(\"Before dropping features:\")\n",
    "print(\"Train columns:\", df_train.columns.tolist())\n",
    "\n",
    "# Drop Name and Ticket (Titles were extracted)\n",
    "df_train = df_train.drop(['Name', 'Ticket'], axis=1)\n",
    "df_test = df_test.drop(['Name', 'Ticket'], axis=1)\n",
    "\n",
    "print(\"\\nAfter dropping features:\")\n",
    "print(\"Train columns:\", df_train.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODING COMPLETE\n",
      "\n",
      "Title encoding mapping:\n",
      "  Master -> 0\n",
      "  Miss -> 1\n",
      "  Mr -> 2\n",
      "  Mrs -> 3\n",
      "  Officer -> 4\n",
      "  Royalty -> 5\n",
      "FINAL DATASET PREVIEW:\n",
      "\n",
      "Training set shape: (891, 12)\n",
      "Test set shape: (418, 11)\n",
      "\n",
      "Training set data types:\n",
      "Survived        int64\n",
      "Pclass          int64\n",
      "Sex             int64\n",
      "Age           float64\n",
      "SibSp           int64\n",
      "Parch           int64\n",
      "Fare          float64\n",
      "Embarked        int64\n",
      "HasCabin        int64\n",
      "Title           int64\n",
      "FamilySize      int64\n",
      "IsAlone         int64\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n",
      "   Survived  Pclass  Sex        Age  SibSp  Parch     Fare  Embarked  \\\n",
      "0         0       3    1  22.000000      1      0   7.2500         0   \n",
      "1         1       1    0  38.000000      1      0  71.2833         1   \n",
      "2         1       3    0  26.000000      0      0   7.9250         0   \n",
      "3         1       1    0  35.000000      1      0  53.1000         0   \n",
      "4         0       3    1  35.000000      0      0   8.0500         0   \n",
      "5         0       3    1  29.699118      0      0   8.4583         2   \n",
      "6         0       1    1  54.000000      0      0  51.8625         0   \n",
      "7         0       3    1   2.000000      3      1  21.0750         0   \n",
      "8         1       3    0  27.000000      0      2  11.1333         0   \n",
      "9         1       2    0  14.000000      1      0  30.0708         1   \n",
      "\n",
      "   HasCabin  Title  FamilySize  IsAlone  \n",
      "0         0      2           2        0  \n",
      "1         1      3           2        0  \n",
      "2         0      1           1        1  \n",
      "3         1      3           2        0  \n",
      "4         0      2           1        1  \n",
      "5         0      2           1        1  \n",
      "6         1      2           1        1  \n",
      "7         0      0           5        0  \n",
      "8         0      3           3        0  \n",
      "9         0      3           2        0  \n",
      "\n",
      "==================================================\n",
      "FINAL VERIFICATION:\n",
      "Missing values in train: 0\n",
      "Missing values in test: 0\n",
      "\n",
      "Final features for modeling:\n",
      "['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'HasCabin', 'Title', 'FamilySize', 'IsAlone']\n"
     ]
    }
   ],
   "source": [
    "# Sex: male=1, female=0\n",
    "df_train['Sex'] = df_train['Sex'].map({'male': 1, 'female': 0})\n",
    "df_test['Sex'] = df_test['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "# Embarked: S=0, C=1, Q=2\n",
    "df_train['Embarked'] = df_train['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "df_test['Embarked'] = df_test['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "# Title: Use Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_title = LabelEncoder()\n",
    "df_train['Title'] = le_title.fit_transform(df_train['Title'])\n",
    "df_test['Title'] = le_title.transform(df_test['Title'])\n",
    "\n",
    "print(\"ENCODING COMPLETE\")\n",
    "print(\"\\nTitle encoding mapping:\")\n",
    "for i, title in enumerate(le_title.classes_):\n",
    "    print(f\"  {title} -> {i}\")\n",
    "\n",
    "print(\"FINAL DATASET PREVIEW:\")\n",
    "print(\"\\nTraining set shape:\", df_train.shape)\n",
    "print(\"Test set shape:\", df_test.shape)\n",
    "\n",
    "print(\"\\nTraining set data types:\")\n",
    "print(df_train.dtypes)\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_train.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL VERIFICATION:\")\n",
    "print(\"Missing values in train:\", df_train.isnull().sum().sum())\n",
    "print(\"Missing values in test:\", df_test.isnull().sum().sum())\n",
    "\n",
    "# Show final column list\n",
    "print(\"\\nFinal features for modeling:\")\n",
    "print([col for col in df_train.columns if col != 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (891, 11)\n",
      "Training labels shape: (891,)\n",
      "Test features shape: (418, 11)\n",
      "\n",
      "Split data:\n",
      "  Training: 712 samples\n",
      "  Validation: 179 samples\n",
      "  Survival rate in train: 0.383\n",
      "  Survival rate in val: 0.385\n"
     ]
    }
   ],
   "source": [
    "# IMPORT MODULES and PREPARE X,y TRAINING SPLITS \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Training data\n",
    "X_train = df_train.drop('Survived', axis=1)\n",
    "y_train = df_train['Survived']\n",
    "\n",
    "# Test data (no Survived column)\n",
    "X_test = df_test.copy()\n",
    "\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Test features shape:\", X_test.shape)\n",
    "\n",
    "# Split training data for validation\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_train  # Keep same survival ratio in train/val\n",
    ")\n",
    "\n",
    "print(f\"\\nSplit data:\")\n",
    "print(f\"  Training: {X_tr.shape[0]} samples\")\n",
    "print(f\"  Validation: {X_val.shape[0]} samples\")\n",
    "print(f\"  Survival rate in train: {y_tr.mean():.3f}\")\n",
    "print(f\"  Survival rate in val: {y_val.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL 1: LOGISTIC REGRESSION\n",
      "==================================================\n",
      "\n",
      "Validation Accuracy: 0.8101 (81.01%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.83      0.86      0.85       110\n",
      "    Survived       0.77      0.72      0.75        69\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.80      0.79      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[95 15]\n",
      " [19 50]]\n",
      "\n",
      "5-Fold CV Accuracy: 0.7946 (+/- 0.0160)\n"
     ]
    }
   ],
   "source": [
    "# MODEL 1: Logistic Regression (baseline)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL 1: LOGISTIC REGRESSION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_tr, y_tr)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_model.predict(X_val)\n",
    "\n",
    "# Evaluation\n",
    "lr_accuracy = accuracy_score(y_val, y_pred_lr)\n",
    "print(f\"\\nValidation Accuracy: {lr_accuracy:.4f} ({lr_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_lr, target_names=['Died', 'Survived']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred_lr))\n",
    "\n",
    "# Cross-validation score\n",
    "cv_scores_lr = cross_val_score(lr_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"\\n5-Fold CV Accuracy: {cv_scores_lr.mean():.4f} (+/- {cv_scores_lr.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL 2: RANDOM FOREST\n",
      "==================================================\n",
      "\n",
      "Validation Accuracy: 0.7933 (79.33%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.82      0.85      0.84       110\n",
      "    Survived       0.75      0.70      0.72        69\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.78      0.78      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[94 16]\n",
      " [21 48]]\n",
      "\n",
      "5-Fold CV Accuracy: 0.8339 (+/- 0.0357)\n",
      "\n",
      "Top 10 Feature Importances (Random Forest):\n",
      "       feature  importance\n",
      "1          Sex    0.261650\n",
      "5         Fare    0.176449\n",
      "2          Age    0.130602\n",
      "8        Title    0.126027\n",
      "0       Pclass    0.083110\n",
      "7     HasCabin    0.080176\n",
      "9   FamilySize    0.053623\n",
      "3        SibSp    0.030839\n",
      "6     Embarked    0.026811\n",
      "4        Parch    0.019468\n",
      "10     IsAlone    0.011246\n"
     ]
    }
   ],
   "source": [
    "# MODEL 2: Random Forest\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL 2: RANDOM FOREST\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_tr, y_tr)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "# Evaluation\n",
    "rf_accuracy = accuracy_score(y_val, y_pred_rf)\n",
    "print(f\"\\nValidation Accuracy: {rf_accuracy:.4f} ({rf_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_rf, target_names=['Died', 'Survived']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred_rf))\n",
    "\n",
    "# Cross-validation score\n",
    "cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"\\n5-Fold CV Accuracy: {cv_scores_rf.mean():.4f} (+/- {cv_scores_rf.std():.4f})\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\nTop 10 Feature Importances (Random Forest):\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting gradient boosting to try to mitigate some of the class imbalances, \n",
    "(i.e. women and children survival: high vs. men survival: low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL 3: XGBoost (Gradient Boosting)\n",
      "==================================================\n",
      "\n",
      "Class imbalance ratio: 1.61\n",
      "  Died (0): 549 samples (61.6%)\n",
      "  Survived (1): 342 samples (38.4%)\n",
      "\n",
      "Validation Accuracy: 0.8101 (81.01%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.85      0.84      0.84       110\n",
      "    Survived       0.75      0.77      0.76        69\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.80      0.80      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[92 18]\n",
      " [16 53]]\n",
      "  True Negatives:  92 (correctly predicted deaths)\n",
      "  False Positives: 18 (predicted survived, actually died)\n",
      "  False Negatives: 16 (predicted died, actually survived)\n",
      "  True Positives:  53 (correctly predicted survivals)\n",
      "\n",
      "5-Fold CV Accuracy: 0.8361 (+/- 0.0217)\n",
      "\n",
      "Top Feature Importances (XGBoost):\n",
      "       feature  importance\n",
      "1          Sex    0.552948\n",
      "7     HasCabin    0.122148\n",
      "0       Pclass    0.121143\n",
      "8        Title    0.037144\n",
      "5         Fare    0.033725\n",
      "6     Embarked    0.031595\n",
      "2          Age    0.031233\n",
      "9   FamilySize    0.030717\n",
      "3        SibSp    0.024068\n",
      "4        Parch    0.015278\n",
      "10     IsAlone    0.000000\n"
     ]
    }
   ],
   "source": [
    "# MODEL 3: XGBoost \n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL 3: XGBoost (Gradient Boosting)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate scale_pos_weight to handle imbalance\n",
    "# scale_pos_weight = (# negative samples) / (# positive samples)\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"\\nClass imbalance ratio: {scale_pos_weight:.2f}\")\n",
    "print(f\"  Died (0): {(y_train == 0).sum()} samples ({(y_train == 0).sum()/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  Survived (1): {(y_train == 1).sum()} samples ({(y_train == 1).sum()/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=scale_pos_weight,  # Handle imbalance\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_tr, y_tr)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = xgb_model.predict(X_val)\n",
    "\n",
    "# Evaluation\n",
    "xgb_accuracy = accuracy_score(y_val, y_pred_xgb)\n",
    "print(f\"\\nValidation Accuracy: {xgb_accuracy:.4f} ({xgb_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_xgb, target_names=['Died', 'Survived']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_xgb = confusion_matrix(y_val, y_pred_xgb)\n",
    "print(cm_xgb)\n",
    "print(f\"  True Negatives:  {cm_xgb[0,0]} (correctly predicted deaths)\")\n",
    "print(f\"  False Positives: {cm_xgb[0,1]} (predicted survived, actually died)\")\n",
    "print(f\"  False Negatives: {cm_xgb[1,0]} (predicted died, actually survived)\")\n",
    "print(f\"  True Positives:  {cm_xgb[1,1]} (correctly predicted survivals)\")\n",
    "\n",
    "# Cross-validation score\n",
    "cv_scores_xgb = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"\\n5-Fold CV Accuracy: {cv_scores_xgb.mean():.4f} (+/- {cv_scores_xgb.std():.4f})\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\nTop Feature Importances (XGBoost):\")\n",
    "feature_importance_xgb = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(feature_importance_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL 4: LightGBM\n",
      "==================================================\n",
      "\n",
      "Validation Accuracy: 0.8101 (81.01%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Died       0.84      0.85      0.85       110\n",
      "    Survived       0.76      0.74      0.75        69\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.80      0.80      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[94 16]\n",
      " [18 51]]\n",
      "  True Negatives:  94 (correctly predicted deaths)\n",
      "  False Positives: 16 (predicted survived, actually died)\n",
      "  False Negatives: 18 (predicted died, actually survived)\n",
      "  True Positives:  51 (correctly predicted survivals)\n",
      "\n",
      "5-Fold CV Accuracy: 0.8362 (+/- 0.0327)\n",
      "\n",
      "Top Feature Importances (LightGBM):\n",
      "       feature  importance\n",
      "5         Fare         512\n",
      "2          Age         357\n",
      "9   FamilySize          75\n",
      "8        Title          58\n",
      "0       Pclass          48\n",
      "1          Sex          47\n",
      "6     Embarked          47\n",
      "3        SibSp          36\n",
      "4        Parch          31\n",
      "7     HasCabin          26\n",
      "10     IsAlone           1\n",
      "\n",
      "==================================================\n",
      "COMPLETE MODEL COMPARISON\n",
      "==================================================\n",
      "Logistic Regression CV Accuracy: 0.7946 (+/- 0.0160)\n",
      "Random Forest CV Accuracy:       0.8339 (+/- 0.0357)\n",
      "XGBoost CV Accuracy:             0.8361 (+/- 0.0217)\n",
      "LightGBM CV Accuracy:            0.8362 (+/- 0.0327)\n",
      "\n",
      "==================================================\n",
      "LEADERBOARD:\n",
      "==================================================\n",
      "#1: LightGBM                  0.8362\n",
      "#2: XGBoost                   0.8361\n",
      "#3: Random Forest             0.8339\n",
      "#4: Logistic Regression       0.7946\n",
      "\n",
      " Champion: LightGBM with 0.8362 accuracy\n",
      "\n",
      "Margin of victory: 0.0000 (0.00%)\n",
      "Models are statistically tied - difference is likely noise\n"
     ]
    }
   ],
   "source": [
    "# MODEL 4: LightGBM\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL 4: LightGBM\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "lgbm_model = LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    scale_pos_weight=scale_pos_weight,  # Handle imbalance\n",
    "    random_state=42,\n",
    "    verbose=-1  # Suppress warnings\n",
    ")\n",
    "\n",
    "lgbm_model.fit(X_tr, y_tr)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lgbm = lgbm_model.predict(X_val)\n",
    "\n",
    "# Evaluation\n",
    "lgbm_accuracy = accuracy_score(y_val, y_pred_lgbm)\n",
    "print(f\"\\nValidation Accuracy: {lgbm_accuracy:.4f} ({lgbm_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_lgbm, target_names=['Died', 'Survived']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_lgbm = confusion_matrix(y_val, y_pred_lgbm)\n",
    "print(cm_lgbm)\n",
    "print(f\"  True Negatives:  {cm_lgbm[0,0]} (correctly predicted deaths)\")\n",
    "print(f\"  False Positives: {cm_lgbm[0,1]} (predicted survived, actually died)\")\n",
    "print(f\"  False Negatives: {cm_lgbm[1,0]} (predicted died, actually survived)\")\n",
    "print(f\"  True Positives:  {cm_lgbm[1,1]} (correctly predicted survivals)\")\n",
    "\n",
    "# Cross-validation score\n",
    "cv_scores_lgbm = cross_val_score(lgbm_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"\\n5-Fold CV Accuracy: {cv_scores_lgbm.mean():.4f} (+/- {cv_scores_lgbm.std():.4f})\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\nTop Feature Importances (LightGBM):\")\n",
    "feature_importance_lgbm = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': lgbm_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(feature_importance_lgbm)\n",
    "\n",
    "# ============================================\n",
    "# COMPLETE MODEL COMPARISON\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPLETE MODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Logistic Regression CV Accuracy: {cv_scores_lr.mean():.4f} (+/- {cv_scores_lr.std():.4f})\")\n",
    "print(f\"Random Forest CV Accuracy:       {cv_scores_rf.mean():.4f} (+/- {cv_scores_rf.std():.4f})\")\n",
    "print(f\"XGBoost CV Accuracy:             {cv_scores_xgb.mean():.4f} (+/- {cv_scores_xgb.std():.4f})\")\n",
    "print(f\"LightGBM CV Accuracy:            {cv_scores_lgbm.mean():.4f} (+/- {cv_scores_lgbm.std():.4f})\")\n",
    "\n",
    "# Find best model\n",
    "results = {\n",
    "    'Logistic Regression': cv_scores_lr.mean(),\n",
    "    'Random Forest': cv_scores_rf.mean(),\n",
    "    'XGBoost': cv_scores_xgb.mean(),\n",
    "    'LightGBM': cv_scores_lgbm.mean()\n",
    "}\n",
    "\n",
    "# Sort by accuracy\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LEADERBOARD:\")\n",
    "print(\"=\"*50)\n",
    "for rank, (model_name, score) in enumerate(sorted_results, 1):\n",
    "    print(f\"#{rank}: {model_name:<25} {score:.4f}\")\n",
    "\n",
    "best_model_name = sorted_results[0][0]\n",
    "best_score = sorted_results[0][1]\n",
    "print(f\"\\n Champion: {best_model_name} with {best_score:.4f} accuracy\")\n",
    "\n",
    "# Compare top 2\n",
    "if len(sorted_results) > 1:\n",
    "    gap = sorted_results[0][1] - sorted_results[1][1]\n",
    "    print(f\"\\nMargin of victory: {gap:.4f} ({gap*100:.2f}%)\")\n",
    "    if gap < 0.005:  # Less than 0.5% difference\n",
    "        print(\"Models are statistically tied - difference is likely noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature importance ranking for LightGBM is interesting but not surprising. Ticket 'Fare' is indicative of wealth. Those who paid the most money were likely weatlthy and therefore priority for life boats. \n",
    "\n",
    "Also, 'Title' ranking higher in importance than 'Sex' makes sense because it captures gender along with the social status making 'Sex' somewhat redundant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final LightGBM model on all data\n",
      "Model trained\n",
      "Generated 418 predictions\n",
      "\n",
      "Making predictions on test set\n",
      "\n",
      "Test set predictions: 418 samples\n",
      "Predicted survivors: 164 (39.2%)\n",
      "Predicted deaths: 254 (60.8%)\n",
      "\n",
      "Training set survival rate: 38.4%\n",
      "Test set predicted survival rate: 39.2%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training final LightGBM model on all data\")\n",
    "\n",
    "# Retrain the model\n",
    "final_model = LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "print(\"Model trained\")\n",
    "\n",
    "# Generate predictions\n",
    "test_predictions = final_model.predict(X_test)\n",
    "print(f\"Generated {len(test_predictions)} predictions\")\n",
    "\n",
    "print(\"\\nMaking predictions on test set\")\n",
    "test_predictions = final_model.predict(X_test)\n",
    "\n",
    "print(f\"\\nTest set predictions: {len(test_predictions)} samples\")\n",
    "print(f\"Predicted survivors: {test_predictions.sum()} ({test_predictions.sum()/len(test_predictions)*100:.1f}%)\")\n",
    "print(f\"Predicted deaths: {(test_predictions == 0).sum()} ({(test_predictions == 0).sum()/len(test_predictions)*100:.1f}%)\")\n",
    "\n",
    "# Compare with training set survival rate\n",
    "print(f\"\\nTraining set survival rate: {y_train.mean()*100:.1f}%\")\n",
    "print(f\"Test set predicted survival rate: {test_predictions.mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission CSV file created\n"
     ]
    }
   ],
   "source": [
    "def save_preds(fn, y_pred, passenger_ids):\n",
    "    import csv\n",
    "    with open(fn, 'w') as fout:\n",
    "        writer = csv.writer(fout, delimiter=',', lineterminator='\\n')\n",
    "        writer.writerow(['PassengerId', 'Survived'])\n",
    "        for pid, pred in zip(passenger_ids, y_pred):\n",
    "            writer.writerow([pid, pred])\n",
    "\n",
    "save_preds('titanic_survival predictions_bruce.csv', test_predictions, test_ids)\n",
    "print(\"Submission CSV file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My submission results %74.64\n",
    "This tells me my model learned patterns specific to the training set that did not generalize well to the test  data, overfitting. The Maybe I could have dropped Cabin information, and it was added noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
